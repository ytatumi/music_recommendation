{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_df = pd.read_csv(\"tracks_2000.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>bpm</th>\n",
       "      <th>energy</th>\n",
       "      <th>danceability</th>\n",
       "      <th>dB</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>duration</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>118</td>\n",
       "      <td>68</td>\n",
       "      <td>71</td>\n",
       "      <td>-4</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupid - Twin Ver.</td>\n",
       "      <td>FIFTY FIFTY</td>\n",
       "      <td>k-pop girl group</td>\n",
       "      <td>2023</td>\n",
       "      <td>120</td>\n",
       "      <td>59</td>\n",
       "      <td>78</td>\n",
       "      <td>-8</td>\n",
       "      <td>35</td>\n",
       "      <td>73</td>\n",
       "      <td>174</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BESO</td>\n",
       "      <td>ROSALÍA</td>\n",
       "      <td>pop</td>\n",
       "      <td>2023</td>\n",
       "      <td>95</td>\n",
       "      <td>64</td>\n",
       "      <td>77</td>\n",
       "      <td>-7</td>\n",
       "      <td>17</td>\n",
       "      <td>53</td>\n",
       "      <td>195</td>\n",
       "      <td>74</td>\n",
       "      <td>14</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boy's a liar Pt. 2</td>\n",
       "      <td>PinkPantheress</td>\n",
       "      <td>bronx drill</td>\n",
       "      <td>2023</td>\n",
       "      <td>133</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>-8</td>\n",
       "      <td>25</td>\n",
       "      <td>86</td>\n",
       "      <td>131</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creepin' (with The Weeknd &amp; 21 Savage)</td>\n",
       "      <td>Metro Boomin</td>\n",
       "      <td>rap</td>\n",
       "      <td>2022</td>\n",
       "      <td>98</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>-6</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>222</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title          artist         top genre  \\\n",
       "0                                 Flowers     Miley Cyrus               pop   \n",
       "1                       Cupid - Twin Ver.     FIFTY FIFTY  k-pop girl group   \n",
       "2                                    BESO         ROSALÍA               pop   \n",
       "3                      Boy's a liar Pt. 2  PinkPantheress       bronx drill   \n",
       "4  Creepin' (with The Weeknd & 21 Savage)    Metro Boomin               rap   \n",
       "\n",
       "   year  bpm  energy  danceability   dB  liveness  valence  duration  \\\n",
       "0  2023  118      68             71  -4         3       65       200   \n",
       "1  2023  120      59             78  -8        35       73       174   \n",
       "2  2023   95      64             77  -7        17       53       195   \n",
       "3  2023  133      81             70  -8        25       86       131   \n",
       "4  2022   98      62             72  -6         8       17       222   \n",
       "\n",
       "   acousticness  speechiness   popularity  \n",
       "0             6             7          98  \n",
       "1            44             3          97  \n",
       "2            74            14          96  \n",
       "3            25             5          96  \n",
       "4            42             5          96  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tracks_df.loc[: ,\"artist\":]\n",
    "y = tracks_df[\"popularity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest=train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['artist', 'top genre','year']\n",
    "num_col = tracks_df.iloc[: , 4:].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_transform = ColumnTransformer([(\"ohe\",OneHotEncoder(handle_unknown= 'ignore', sparse=False), cat_col),(\"normalization\", MinMaxScaler(),num_col)], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed=col_transform.fit_transform(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_transformed=col_transform.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1987, 1193)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(x_train_transformed.shape[1],64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,1),           \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "net = Net()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1193])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([32])\n",
      "torch.Size([1, 32])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i in range (len(list(net.parameters()))):\n",
    "    print(list(net.parameters())[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SongsDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = torch.tensor(x, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype = torch.float32).clone().reshape(y.shape[0],1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features = self.x[idx]\n",
    "        target = self.y[idx]\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SongsDataset(x_train_transformed, ytrain.values)\n",
    "test_dataset = SongsDataset(x_test_transformed, ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2834.9820\n",
      "Epoch 2/10, Loss: 77.6596\n",
      "Epoch 3/10, Loss: 43.2156\n",
      "Epoch 4/10, Loss: 29.8642\n",
      "Epoch 5/10, Loss: 24.5116\n",
      "Epoch 6/10, Loss: 21.1626\n",
      "Epoch 7/10, Loss: 20.6873\n",
      "Epoch 8/10, Loss: 18.5959\n",
      "Epoch 9/10, Loss: 17.3243\n",
      "Epoch 10/10, Loss: 15.6516\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter(\"runs/music\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "num_epochs =10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for features, popularity in train_loader:\n",
    "        \n",
    "        features = features.to(device)\n",
    "        popularity = popularity.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(features)\n",
    "        loss = criterion(outputs, popularity)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "    writer.add_scalar(\"training_loss\", running_loss/100, epoch * n_total_steps + i)\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13.2642)\n",
      "tensor(8.8720)\n",
      "tensor(9.0891)\n",
      "tensor(10.4043)\n",
      "tensor(17.4125)\n",
      "tensor(13.3261)\n",
      "tensor(12.4669)\n",
      "tensor(12.8462)\n",
      "tensor(9.8252)\n",
      "tensor(10.0000)\n",
      "tensor(11.9716)\n",
      "tensor(6.7809)\n",
      "tensor(8.0062)\n",
      "tensor(8.2824)\n",
      "tensor(9.9053)\n",
      "tensor(11.0431)\n",
      "tensor(11.1329)\n",
      "tensor(7.6373)\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "total_loss = 0 \n",
    "with torch.no_grad():\n",
    "    for features, popularity in test_loader:\n",
    "\n",
    "        features = features.to(device)\n",
    "        popularity = popularity.to(device)\n",
    "        outputs = net(features)\n",
    "        loss = criterion(outputs, popularity)\n",
    "        print(loss)\n",
    "        total_loss += loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.6814)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss = total_loss/len(test_loader)\n",
    "avg_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2682483\n"
     ]
    }
   ],
   "source": [
    "torch_rmse = torch.sqrt(avg_loss).detach().numpy()\n",
    "print(torch_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "047a835ead3760a3930a1fe5995899ec416b638237db5aa60292e1395323ca4f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
